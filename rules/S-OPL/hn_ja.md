
[日本語](./hn_ja.md) | [English](./hn_en.md)

# Human Navigation（HN）

## 概要
このタスクの目的は日常生活環境におけるいくつかのタスクを達成するために，
ロボットが人間に対して親しみやすくシンプルな自然言語表現を生成して案内するものです.

例えば，"目の前のテーブルの上にあるコップをキッチンの2段目の引き出しまで運んでください"といったように、  
ロボットは特定の物体を指定された目的地まで運ぶための自然言語による指示を行います。  
人（被験者）は仮想現実のアバターにログインし、その指示に従います。  
被験者はロボットの指示に従い、VRセットを使用して対象物を手に取り、目的地まで運ぶことを試みます。  
対象物の操作を完了するまでの所要時間を計測し、それに基づいてポイントが算出されます。  
人間にとって最も簡単で自然な指示を生成したチームが、より高いポイントを獲得できるはずです。

## セットアップ
- **システム構成**:
  - 本競技ではシミュレーション環境を実行するWindows PCと，各チームが開発するロボットコントローラを実行するUbuntu PCでrosbridge serverを介した通信を行う．これにより，ロボットのセンサデータの取得や，アバターとロボットのインタラクションを行う．
- **Human Navigation-Windows**:
  - シミュレーション環境を実行するWindows PCでは，UnityとSIGVerseをベースにHuman navigationソフトウェアを実行する．このソフトウェアは，JointState，TF，センサー情報，その他のROSメッセージを一定間隔でロボットコントローラに送信する．セットアップ手順は[こちら](https://github.com/RoboCupatHomeSim/human-navigation-unity)．
- **ロボットコントローラ-Ubuntu**: 
  - 各チームはUbuntu環境において，Human navigationタスクを行うためのロボット制御プログラムの開発を行う．TwistやJointTrajectory，その他のROSメッセージを送信することでロボットを制御する．Ubuntu環境のセットアップ手順は[こちら](https://wiki.ros.org/noetic/Installation/Ubuntu)．

## 競技の構成
競技の流れは以下の通りです．

1. チームメンバーがSIGVerse ROSBridgeサーバ，ロボットコントローラを起動する．

2. 技術委員(TC)がHuman Navigatioin プログラムを起動する．

3. 被験者がOculus Rift & Touchを装着．

4. 被験者がセッション開始ボタンを押す．

5. 競技用の環境を読み込み，アバターの位置と向きを初期化する．

6. モデレータがロボットに"Are_you_ready?"メッセージを送信する．

7. ロボットがモデレータに"I_am_ready"メッセージを送信する．

8. モデレータがロボットにTaskInfoを送信する．TaskInfoには，目標物と目的地が含まれる．

9. ロボットは，guidance_messageを生成し，ロボットに送信する．
ロボットは任意のタイミングでguidance_messageを送信できる．

10. 被検者は，guidance_messageに従って，目標物を取り，指定された場所（目的地）に置く．
被検者はguidance_messageを要求することができる．被験者が新たなguidance_messageを要求すると，
"Guidance_request"メッセージがロボットに送信される．
> [!WARNING]
> 指示回数が**15回**を超えた場合，ペナルティが与えられる．

11. 目標物を把持した場合，ポイントが加算される．
> [!WARNING]
> 対象物が把持される前に，誤った対象物が把持された場合，ペナルティが与えられる．

12. 目標物が目的地に入れば，得点が加算される．

13. 各セッションは以下のイベントによって終了する．
- **目標物が目的地に設置される場合**:
  - モデレータからロボットに"Task_succeeded"が送信される．
- **ロボットコから"Give_up"が送信される場合**:
  - タスクが達成できない場合，ロボットは"Give_up"メッセージを送ることができる．
  - その場合，セッションは中断され，モデレータは"Task_failed"メッセージをロボットに送信する．
- **時間切れの場合**:
  - モデレータはロボットに"Task_failed"メッセージを送信する．
- **セッションが残っていない場合**:
  - モデレータはロボットに"Mission_complete"メッセージを送信し，競技を終了する．
- **セッションが残っている場合**:
  - モデレータはロボットに  "Go_to_next_session"メッセージを送信する．
  - 被験者は次のチームエリアに移動し，Oculus Rift & Touchを装着する．
  - オペレータはGo_to_next_sessionボタンを押す．
  - ステップ5に戻る．

> [!Tip]
> 詳細はGithubの[wiki](https://github.com/RoboCupatHomeSim/human-navigation-unity/wiki/SystemOverview)を参照してください．

## セッション数と制限時間
タスクは**8**セッションで構成され，各セッションの制限時間は**3**分です．
タイマーは，TCがスタートボタンをクリックした時点で開始されます．

## スコアシート

<table>
  <tr>
    <th> <b>Action</b> </th>
    <th> <b>Score</b> </th>
  </tr>
  <tr>
    <td colspan="2" align="center"> <b>メインタスク</b> </td>
  </tr>
  <tr>
    <td> アバターが対象物を把持する<br> 
      アバターが対象物を目的地に入れる/載せる <br> 
    </td>
    <td align="center"> 20 <br> 20<br> </td>
  </tr>
  <tr>
    <td colspan="2" align="center"> <b> ボーナスポイント </b> </td>
  </tr>
  <tr>
    <td> 対象物を掴むまでの時間ボーナス<br> 
    対象物を置くまでの時間ボーナス 
    </td>
    <td align="center"><sup>remaining time</sup>&frasl;<sub>time limit</sub>*60<br><sup>remaining time</sup>&frasl;<sub>time limit</sub>*60</td>
    </td>
  </tr>
  <tr>
    <td colspan="2" align="center"> <b> ペナルティ </b> </td>
  </tr>
  <tr>
    <td>間違ったオブジェクトを把持する(各オブジェクトに対して1回)<br>
    指示文の最大数を超える<br>
    ロボットが把持対象物体の α [m] 以内に侵入する <br>
    ロボットが目的地の α [m] 以内に侵入する<br>
    ロボットがアバター以外と衝突する (各回)
    </td>
    <td align="center"> -5 <br> -3 <br> -40<br> -40<br> -10</td>
  </tr>
  <tr>
    <td> <b>総得点 (ペナルティ，ボーナスを除く) （1セッション当たり）</b> </td>
    <td align="center"> <b>40</b> </td>
  </tr>
</table>

実際に使用する課題は平等を期すために各チームで作成したものを用いる．

タイムボーナスは，time_limitとremaining_timeの2つのパラメータで計算されます．
time_limitはNに等しく，remaining_timeはアバターが対象物を掴んだり置いたりした時の残り時間です．

被験者には，得点，ペナルティ，タイムボーナスを事前に説明し，理解しているものとします．


##  仮想環境のレイアウト
GitHub からいくつかの環境例が公開されています．

- 競技に使用するオブジェクトは，把持対象候補，関連しない物体，家具から構成されます．
これらは，競技会の14日前までにUnityのプロジェクトファイルとして提供されます．
- 部屋のレイアウト情報は，Unityのプロジェクトファイルとして提供されます．
レイアウトの種類は，セッション数（≦M）までとします．
セッション開始時に，システムからルームレイアウトIDが送信されます．
ルームレイアウトとレイアウトIDは，大会の24時間前までに発表される予定です．
- レイアウトの部屋数は常に1つです．
壁やドアで仕切られていない大きな部屋となります．
- 複数種類の環境を用意する予定です．

## レフェリー(TC)の動き
- 競技開始30分前に集まり，競技者とともに接続確認を行う．
- スコアシートに基づき，競技を採点する．
- 他のTCと採点内容を確認し合う．
- スコアシートを提出する．

> [!NOTE]
> TCは各チームから数名選出され，他チームの競技において上記を行ってもらう．

## 備考

### 操作する物体
- 把持可能なオブジェクトの3Dモデルやプレハブの名称は事前に公開します．
- 物体の位置，量，種類はセッションごとに変化します．
- 同一の物体が環境中に配置されることもあります．
- タスク開始時に各物体の初期位置をロボットに送信します．
ただし，このメッセージには，オブジェクトが置かれている家具などの情報は含まれていません．
- 使用されるオブジェクト名は，競技前に発表されるオブジェクトリストに示される「プレハブ名」情報に対応しています．


### ロボットの初期位置・姿勢
全セッションにおいて，ロボットの初期位置・姿勢は（x, y, z, θ）=（0, 0, 0, 0）です．


### タスク情報を参照するためのROS通信
- チームは，ROS通信を利用して，以下のタスク情報を参照することができます:
  - ルームレイアウトID
  - 対象オブジェクトのプレハブ名・位置・向き
  - 把持対象物体を置く指定領域の位置，向き，大きさ
  - 把持対象物体と家具以外の把持可能なオブジェクトのプレハブ名，位置，向きのリスト
  - 家具オブジェクトのプレハブ名と位置のリスト
- 通信プロトコルはGitHubで詳細に定義されています．


### ロボットからの指示
- ロボットはいつでも自然言語による指示を出すことができます．
- 自然言語による指示は，口頭（[SAPI](https://learn.microsoft.com/en-us/previous-versions/windows/desktop/ms720151(v=vs.85))使用）と視覚（Unityのメッセージボード効果使用）で被験者に提供されます．
- メッセージボードは，ロボットの上とアバターの前に表示される2つのボードを使用することができます．
- その仮想メッセージボードに数秒間，指示文が表示されます．それぞれのメッセージボードを使うかどうかは，チームが選択することができます．
- 指示文の文字数は400文字以内とします．
- ロボットからの指示は15回までとします．制限を超えた場合，追加の指示ごとに-3点のペナルティが課されます．
- ロボットはジェスチャーで目的地を指示することができますが，目的地からα[m]（1 ≦ α ≦ 5）以内に近づくと，-40点のペナルティを課します．αは大会の7日前までに発表する．
- アバターや把持可能な物体はロボットと衝突することはありませんので，アバターや把持可能な物体にロボットが衝突してもペナルティはありません．
ロボットが静止物（家具など）に衝突した場合は，-10点のペナルティを与えます．
- 被験者は，Oculus Touchのボタンを使って，いつでも自然言語の指示を要求することができます．
この要求に対してロボットが返信した場合，その返信は指示としてカウントされます．
また，ロボットはこの要求を無視することもできます．
- 練習中，被験者は，タスクを中断してOculus Homeを表示することにつながるOculus Buttonを押さないことを学びます．
また，誤操作を防ぐために，長押し以外ではOculus Buttonを作動させないようにオキュラスソフトウェアの設定を行います．
万が一，被験者がOculus Homeのシーンを開いてしまった場合は，できるだけ早くOculusボタンを押すことでセッションに復帰します．
そのために，被験者は練習中にOculus Homeシーンからセッションに戻る方法も学びます．
- Oculus Homeを表示した後，短時間（例えば5秒）で被験者がセッションに戻ることができなかった場合，チームは再試行を要求することができます．
この場合，新しいスコアが最初のスコアより低かったとしても，採用されます．
もちろん，部屋のレイアウトに関する知識がなく，利益相反のない新しい被験者が選ばれます．


### 仮想アバターにログインする被験者
- 被験者がロボットに質問することはできません．
- 競技との間に利益相反がない被験者を実行委員会が選出します．
- 被験者には，環境について何も知らせません．
- 被験者にはテスト環境において，物体の移動・把持，ドアや引き出しの開閉，ロボットへの指示出しなどの操作手順を事前に説明します．
- 得点，罰則，タイムボーナスを事前に伝えます．
- 名前と外見の対応付けを事前に被験者に示します．
しかし，被験者が常に名前を覚えているとは限りません．
被験者が名前を理解できなくても，主催者の責任ではありません．
チームは，被験者が物や家具を含む文章を理解できるようにする責任があります．


### アバターやオブジェクトの進行状況を参照するためのROS通信
- ロボットはアバターに関する以下の情報をペナルティなく参照することができます:
  - アバターの頭，胴体，両手の位置と向き
  - 把持した物体の名称と，把持した物体が対象物体であるか否か
- ロボットは把持可能な物体に関する以下の情報をペナルティなしに参照することができます:
  - 引き出しやドアの取っ手を除く，すべての把持可能な物体の位置と方向


### VR関連のデバイス
- アバターの操作には，被験者が以下の機器を使用します:
  - Oculus Rift & Touch
  - 有線イヤホン
  - 防音用イヤーマフ


### 被験者の音声ガイダンス - Voice Guidance for Participants
- SAPIが使用する指示文の音声をWindowsPCが合成します．
被験者は合成音声を聞くために常にイヤホンを装着します．
- イヤーマフを装着しているため，他チームの合成音声は聞こえない状態です．
- SAPIは競技委員会が用意したコンピュータ上で実行されます．
- ロボットから新しい指示メッセージが送られてきたときに，合成音声が話し終わっていない場合は，前の合成音声はキャンセルされ，新しい合成音声が再生されます．
